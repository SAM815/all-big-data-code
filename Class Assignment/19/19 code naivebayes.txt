import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.classification.{LogisticRegression, LinearSVC, NaiveBayes}
import org.apache.spark.sql.types.DoubleType
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.sql.Row
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator

val spark = SparkSession.builder().appName("ClassificationExample").getOrCreate()

val df = spark.read.format("csv")
            .option("header", "false")
			.option("InferSchema","true")
            .load("input/input.txt")
            .select("_c1","_c2","_c3","_c4","_c5" )
            .toDF("diag", "radius", "texture", "perimeter", "area")

val featureCols = Array("radius", "texture", "perimeter", "area")
val assembler = new VectorAssembler()
                .setInputCols(featureCols)
                .setOutputCol("features")

val assembledData = assembler.transform(df)
val indexer = new StringIndexer().setInputCol("diag").setOutputCol("label")

val data = indexer.fit(assembledData).transform(assembledData)

val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))

// Logistic Regression
val lr = new LogisticRegression()
val lrModel = lr.fit(trainingData)
val lrPredictions = lrModel.transform(testData)
val lrEvaluator = new MulticlassClassificationEvaluator()
                .setLabelCol("label")
                .setPredictionCol("prediction")
                .setMetricName("accuracy")
val lrAccuracy = lrEvaluator.evaluate(lrPredictions)
val lrTestError = (1.0 - lrAccuracy) * 100
println(s"Logistic Regression Test Error: $lrTestError%")

// Support Vector Machine (SVM)
val svm = new LinearSVC()
val svmModel = svm.fit(trainingData)
val svmPredictions = svmModel.transform(testData)
val svmAccuracy = lrEvaluator.evaluate(svmPredictions)
val svmTestError = (1.0 - svmAccuracy) * 100
println(s"SVM Test Error: $svmTestError%")

// Naive Bayes
val nb = new NaiveBayes()
val nbModel = nb.fit(trainingData)
val nbPredictions = nbModel.transform(testData)
val nbAccuracy = lrEvaluator.evaluate(nbPredictions)
val nbTestError = (1.0 - nbAccuracy) * 100
println(s"Naive Bayes Test Error: $nbTestError%")

spark.stop()